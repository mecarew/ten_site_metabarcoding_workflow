---
title: "01_miseq_run_statistics"
author: "Melissa Carew"
date: "09/11/2025"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

---
title: "raw_metabarcoding_data_stats calculations"
author: "Melissa Carew"
date: "2023-12-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(dplyr)
library(vegan)
```


```{r}
# input unflitered metabarcoding data with final taxonomy
metab_fil <- read.csv("~/git/ten_site_metabarcoding/metabarcoding_workflow/results/ten_site_data_summaries/ten_sites_vsearch_data_summary_filled_long_format_09_11_2025.csv")

# input  finL flitered metabarcoding data     
metab_filt <- read.csv("~/git/ten_site_metabarcoding/metabarcoding_workflow/results/ten_site_data_summaries/ten_sites_long_format_09_11_2025.csv")
```


# MACROINVERTEBRATE SAMPLE DNA METABARCODING
 
# Format metabarcoding data for stats analysis
 
# reads per sample per replicate
```{r}
# create a table of reads for each PCR replicate for each sample and totals unfilitered
metab_fil_reads <- metab_fil %>%
  dplyr::group_by(site_per, replicate) %>%
  summarise(reads = sum(reads))

metab_fil_reads_tab <- spread(metab_fil_reads, key = replicate, value = reads)

# create a table of reads for each PCR replicate for each sample and total
metab_filt_reads <- metab_filt %>%
  dplyr::group_by(site_per, replicate) %>%
  summarise(reads = sum(reads))

metab_filt_reads_tab <- spread(metab_filt_reads, key = replicate, value = reads)

# add total reads
metab_fil_reads_tab$total <- metab_fil_reads_tab$rep1 + metab_fil_reads_tab$rep2

# add total reads
metab_filt_reads_tab$total <-metab_filt_reads_tab$rep1 + metab_filt_reads_tab$rep2

# report minimums in data
lowest_total_reads <- min(metab_fil_reads_tab$total)

lowest_rep_reads <- pmin(metab_fil_reads_tab$rep1, metab_fil_reads_tab$rep2, na.rm = TRUE)
overall_lowest_rep_reads <- min(lowest_rep_reads, na.rm = TRUE)



# rename columns for final supp table
names(metab_fil_reads_tab)[names(metab_fil_reads_tab) == "smpcode"] <- "sample code"
names(metab_fil_reads_tab)[names(metab_fil_reads_tab) == "rep1"] <- "PCR replicate 1"
names(metab_fil_reads_tab)[names(metab_fil_reads_tab) == "rep2"] <- "PCR replicate 2"


# Create the directory (with recursive = TRUE to make parent folders if needed)
dir.create(
  here::here("data_analysis/miseq_tables_figs/run_stats"),
  recursive = TRUE,
  showWarnings = FALSE
)

# Write the Excel file
writexl::write_xlsx(
  metab_fil_reads_tab,
  path = here::here("data_analysis/miseq_tables_figs/run_stats/DNA_metabarcoding_reads_summary.xlsx")
)

print(paste("lowest_total_reads =", lowest_total_reads))
print(paste("overall_lowest_rep_reads =", overall_lowest_rep_reads))

```
# rarefaction both amplicons
```{r}
# Read the CSV (note: escape the space in the filename)
metab_data_wide <- read.csv(
  "~/git/ten_site_metabarcoding/metabarcoding_workflow/results/ten_site_data_summaries/ten_sites_vsearch_data_summary_filled_09_11_2025.csv"
)

# Select only asv_code and the desired columns
raref_data_wide <- metab_data_wide %>%
  select(asv_code, X10WMI2320rep1:X30DNG79574rep2)

# Remove non-numeric columns like ASV IDs if they exist
asv_mat <- raref_data_wide[, -1]  # assuming first column is ASV ID

# Ensure data are numeric
asv_mat <- as.data.frame(sapply(asv_mat, as.numeric))

sample_sums <- colSums(asv_mat)
summary(sample_sums)
hist(sample_sums, main = "Read depth per sample", xlab = "Number of reads")

rarefaction_depth <- 10000  # choose based on the histogram

# Rarefy each sample to the chosen depth
asv_rarefied <- rrarefy(t(asv_mat), sample = rarefaction_depth)
asv_rarefied <- t(asv_rarefied)

colSums(asv_rarefied)  # should all equal the rarefaction depth (or less if removed)

# Species richness (observed ASVs)
richness <- specnumber(t(asv_rarefied))

# Shannon diversity
shannon <- diversity(t(asv_rarefied), index = "shannon")

# Simpson diversity
simpson <- diversity(t(asv_rarefied), index = "simpson")

alpha_div <- data.frame(
  Sample = names(richness),
  Richness = richness,
  Shannon = shannon,
  Simpson = simpson
)
alpha_div

# Disable scientific notation
options(scipen = 999)

# Compute x-axis range
x_range <- range(rowSums(t(asv_mat)))

plot.new()  # start fresh plot window
par(mfrow = c(1,1))  # reset layout

# Plot rarefaction curves (no labels, minimal borders)
rarecurve(
  t(asv_mat),
  step = 500,
  sample = rarefaction_depth,
  col = "steelblue",
  label = FALSE,
  cex = 0.1,
  ylab = "ASVs",
  xlab = "Sequencing depth",
  lwd = 2,
  las = 0.2,
  bty = "l",      # left and bottom borders only
  axes = FALSE
)

# Add clean custom axes with non-scientific numbers
axis(1, at = pretty(x_range), labels = pretty(x_range), lwd.ticks = 0.8)
axis(2, las = 1, lwd.ticks = 0.8)

# Add box outline for left and bottom only
box(bty = "l")

# Add red dashed line at the rarefaction depth
abline(v = rarefaction_depth, col = "red", lty = 2)

```
# saved version rarefaction both amplicons
```{r}
 # Open PNG device
png("~/git/ten_site_metabarcoding/data_analysis/rarefaction_plots/rarefaction_plot_both_amplicons_reps.png", width = 2000, height = 1500, res = 300)  # high-res

# Calculate rarefaction curves without plotting
rc <- rarecurve(t(asv_mat), step = 500, sample = rarefaction_depth, label = FALSE, plot = FALSE)

# Convert to a matrix for plotting
max_length <- max(sapply(rc, length))
rc_mat <- sapply(rc, function(x) {
  c(x, rep(NA, max_length - length(x)))
})

# Create x-axis values (sequencing depth)
x_vals <- seq(from = 0, by = 500, length.out = max_length)  # step = 500

# Plot manually with correct x-axis scale
matplot(
  x_vals,
  rc_mat,
  type = "l",
  lty = 1,
  col = "steelblue",
  lwd = 2,
  xlab = "Sequencing depth",
  ylab = "ASVs",
  axes = FALSE,
  frame.plot = FALSE,
  bg = "white"
)

# Add axes manually with black tick labels
axis(1, col = "black", col.axis = "black", lwd = 2)
axis(2, col = "black", col.axis = "black", lwd = 2)
box(lwd = 2, col = "black")  # optional border

dev.off()
```

# rarefaction short amplicon
```{r}
# Read the CSV
metab_data_wide <- read.csv(
  "~/git/ten_site_metabarcoding/metabarcoding_workflow/results/ten_site_data_summaries/ten_sites_vsearch_data_summary_filled_09_11_2025.csv"
)

# Filter only short amplicon rows
metab_data_wide_s <- metab_data_wide %>%
  filter(amplicon == "short")

# Select only asv_code and sample columns
raref_data_wide_s <- metab_data_wide_s %>%
  select(asv_code, X10WMI2320rep1:X30DNG79574rep2)

# Remove non-numeric columns like ASV IDs
asv_mat_s <- raref_data_wide_s[, -1]  # first column is ASV ID

# Ensure numeric
asv_mat_s <- as.data.frame(sapply(asv_mat_s, as.numeric))

# Check read depths
sample_sums_s <- colSums(asv_mat_s)
summary(sample_sums_s)
hist(sample_sums_s, main = "Read depth per sample", xlab = "Number of reads")

# Set rarefaction depth
rarefaction_depth <- 10000  

# Rarefy
asv_rarefied_s <- rrarefy(t(asv_mat_s), sample = rarefaction_depth)
asv_rarefied_s <- t(asv_rarefied)

colSums(asv_rarefied)  # check all equal or less than rarefaction depth

# Alpha diversity metrics
richness_s <- specnumber(t(asv_rarefied_s))
shannon_s <- diversity(t(asv_rarefied_s), index = "shannon")
simpson_s <- diversity(t(asv_rarefied_s), index = "simpson")

alpha_div_s <- data.frame(
  Sample = names(richness),
  Richness = richness,
  Shannon = shannon,
  Simpson = simpson
)

alpha_div

# Plot rarefaction curves
options(scipen = 999)
x_range <- range(rowSums(t(asv_mat_s)))

plot.new()
par(mfrow = c(1,1))

rarecurve(
  t(asv_mat_s),
  step = 500,
  sample = rarefaction_depth,
  col = "steelblue",
  label = FALSE,
  cex = 0.1,
  ylab = "ASVs",
  xlab = "Sequencing depth",
  lwd = 2,
  las = 0.2,
  bty = "l",
  axes = FALSE
)

axis(1, at = pretty(x_range), labels = pretty(x_range), lwd.ticks = 0.8)
axis(2, las = 1, lwd.ticks = 0.8)
box(bty = "l")
abline(v = rarefaction_depth, col = "red", lty = 2)
```

# saved version rarefaction short amplicon
```{r}
# Open PNG device
png("~/git/ten_site_metabarcoding/data_analysis/rarefaction_plots/rarefaction_plot_short_amplicon_reps.png", width = 2000, height = 1500, res = 300)  # high-res

# Calculate rarefaction curves without plotting
rc <- rarecurve(t(asv_mat_s), step = 500, sample = rarefaction_depth, label = FALSE, plot = FALSE)

# Convert to a matrix for plotting
max_length <- max(sapply(rc, length))
rc_mat <- sapply(rc, function(x) {
  c(x, rep(NA, max_length - length(x)))
})

# Create x-axis values (sequencing depth)
x_vals <- seq(from = 0, by = 500, length.out = max_length)  # step = 500

# Plot manually with correct x-axis scale
matplot(
  x_vals,
  rc_mat,
  type = "l",
  lty = 1,
  col = "steelblue",
  lwd = 2,
  xlab = "Sequencing depth",
  ylab = "ASVs",
  axes = FALSE,
  frame.plot = FALSE,
  bg = "white"
)

# Add axes manually with black tick labels
axis(1, col = "black", col.axis = "black", lwd = 2)
axis(2, col = "black", col.axis = "black", lwd = 2)
box(lwd = 2, col = "black")  # optional border

dev.off()
```
# rarefaction right amplicon
```{r}
# Read the CSV
metab_data_wide <- read.csv(
  "~/git/ten_site_metabarcoding/metabarcoding_workflow/results/ten_site_data_summaries/ten_sites_vsearch_data_summary_filled_09_11_2025.csv"
)

# Filter only short amplicon rows
metab_data_wide_r <- metab_data_wide %>%
  filter(amplicon == "right")

# Select only asv_code and sample columns
raref_data_wide_r <- metab_data_wide_r %>%
  select(asv_code, X10WMI2320rep1:X30DNG79574rep2)

# Remove non-numeric columns like ASV IDs
asv_mat_r <- raref_data_wide_r[, -1]  # first column is ASV ID

# Ensure numeric
asv_mat_r <- as.data.frame(sapply(asv_mat_r, as.numeric))

# Check read depths
sample_sums_r <- colSums(asv_mat_r)
summary(sample_sums_r)
hist(sample_sums_r, main = "Read depth per sample", xlab = "Number of reads")

# Set rarefaction depth
rarefaction_depth <- 5000  

# Rarefy
asv_rarefied_r <- rrarefy(t(asv_mat_r), sample = rarefaction_depth)
asv_rarefied_r <- t(asv_rarefied)

colSums(asv_rarefied)  # check all equal or less than rarefaction depth

# Alpha diversity metrics
richness_r <- specnumber(t(asv_rarefied_r))
shannon_r <- diversity(t(asv_rarefied_r), index = "shannon")
simpson_r <- diversity(t(asv_rarefied_r), index = "simpson")

alpha_div_r <- data.frame(
  Sample = names(richness),
  Richness = richness,
  Shannon = shannon,
  Simpson = simpson
)

alpha_div

# Plot rarefaction curves
options(scipen = 999)
x_range <- range(rowSums(t(asv_mat_r)))

plot.new()
par(mfrow = c(1,1))

rarecurve(
  t(asv_mat_r),
  step = 500,
  sample = rarefaction_depth,
  col = "steelblue",
  label = FALSE,
  cex = 0.1,
  ylab = "ASVs",
  xlab = "Sequencing depth",
  lwd = 2,
  las = 0.2,
  bty = "l",
  axes = FALSE
)

axis(1, at = pretty(x_range), labels = pretty(x_range), lwd.ticks = 0.8)
axis(2, las = 1, lwd.ticks = 0.8)
box(bty = "l")
abline(v = rarefaction_depth, col = "red", lty = 2)
```


# saved version rarefaction right amplicon
```{r}
# Open PNG device
png("~/git/ten_site_metabarcoding/data_analysis/rarefaction_plots/rarefaction_plot_right_amplicon_reps.png", width = 2000, height = 1500, res = 300)  # high-res

# Calculate rarefaction curves without plotting
rc <- rarecurve(t(asv_mat_r), step = 500, sample = rarefaction_depth, label = FALSE, plot = FALSE)

# Convert to a matrix for plotting
max_length <- max(sapply(rc, length))
rc_mat <- sapply(rc, function(x) {
  c(x, rep(NA, max_length - length(x)))
})

# Create x-axis values (sequencing depth)
x_vals <- seq(from = 0, by = 500, length.out = max_length)  # step = 500

# Plot manually with correct x-axis scale
matplot(
  x_vals,
  rc_mat,
  type = "l",
  lty = 1,
  col = "steelblue",
  lwd = 2,
  xlab = "Sequencing depth",
  ylab = "ASVs",
  axes = FALSE,
  frame.plot = FALSE,
  bg = "white"
)

# Add axes manually with black tick labels
axis(1, col = "black", col.axis = "black", lwd = 2)
axis(2, col = "black", col.axis = "black", lwd = 2)
box(lwd = 2, col = "black")  # optional border

dev.off()
```
# comparing overlap between replicates for ASV on unfiterrd data
```{r}
# create a table of reads for each asv
metab_asv <- metab_fil %>%
  dplyr::group_by(asv_code, replicate) %>%
  summarise(reads = sum(reads))

# make PCR replicates heading and add read tally
metab_asv <- spread(metab_asv, key = replicate, value = reads)

# tally samples that have a detection in both PCR replicates
count_both_values <- sum(!is.na(metab_asv$rep1) & !is.na(metab_asv$rep2))

# calculate the total number of rows
total_asv <- nrow(metab_asv)

# calculate the proportion of ASV appearing in both PCR replicates
asv_percentage_overlap <- count_both_values / total_asv *100


print(paste("~/git/ten_site_metabarcoding/data_analysis/run_stats/asv_percentage_overlap_btn_PCR_replicates =",asv_percentage_overlap))
```
# comparing overlap between replicates for ASV on unfiterrd data
```{r}
# create a table of reads for each asv
metab_asv <- metab_filt %>%
  dplyr::group_by(asv_code, replicate) %>%
  summarise(reads = sum(reads))

# make PCR replicates heading and add read tally
metab_asv <- spread(metab_asv, key = replicate, value = reads)

# tally samples that have a detection in both PCR replicates
count_both_values <- sum(!is.na(metab_asv$rep1) & !is.na(metab_asv$rep2))

# calculate the total number of rows
total_asv <- nrow(metab_asv)

# calculate the proportion of ASV appearing in both PCR replicates
asv_percentage_overlap <- count_both_values / total_asv *100


print(paste("~/git/ten_site_metabarcoding/data_analysis/run_stats/asv_percentage_overlap_btn_PCR_replicates =",asv_percentage_overlap))
```

# comparing overlap between replicates for species unfiltered
```{r}
# pull out species identifications only by subseting out species data with a <= 97% match to the DNA barcode library
metabar_fil_97 <- subset(metab_fil, max_p_identity >= 97)

# pull out data need for species/PCR replicate comparison and format
metabar_sp <- metabar_fil_97 %>%
  group_by(species, replicate)  %>%
 summarize(reads = sum(reads)) %>%
  ungroup() 
metabar_sp_rep <- spread(metabar_sp, key = replicate, value = reads) # make PCR replicates heading

# tally samples that have a detection in both PCR replicates
count_both_values <- sum(!is.na(metabar_sp_rep$rep1) & !is.na(metabar_sp_rep$rep2))

# calculate the total number of rows
total_rows <- nrow(metabar_sp_rep)

# calculate the proportion of ASV appearing in both PCR replicates
sp_percentage_overlap <- count_both_values / total_rows *100

# remove files no longer needed
rm(metabar_sp)
rm(metabar_sp_rep)

print(paste("species_percentage_overlap_btn_PCR_replicates_unfiltered =",sp_percentage_overlap))
```

# comparing overlap between replicates for species filtered
```{r}
# pull out species identifications only by subseting out species data with a <= 97% match to the DNA barcode library
metabar_fil_97 <- subset(metab_filt, max_p_identity >= 97)

# pull out data need for species/PCR replicate comparison and format
metabar_sp <- metabar_fil_97 %>%
  group_by(species, replicate)  %>%
 summarize(reads = sum(reads)) %>%
  ungroup() 
metabar_sp_rep <- spread(metabar_sp, key = replicate, value = reads) # make PCR replicates heading

# tally samples that have a detection in both PCR replicates
count_both_values <- sum(!is.na(metabar_sp_rep$rep1) & !is.na(metabar_sp_rep$rep2))

# calculate the total number of rows
total_rows <- nrow(metabar_sp_rep)

# calculate the proportion of ASV appearing in both PCR replicates
sp_percentage_overlap <- count_both_values / total_rows *100

# remove files no longer needed
rm(metabar_sp)
rm(metabar_sp_rep)

print(paste("species_percentage_overlap_btn_PCR_replicates_filtered =",sp_percentage_overlap))
```

# How many sequences and ASVs were assigned to speices
```{r}
# total number of ASVs
num_asv <- length(unique(metab_filt$asv_code))

#short amplicon (BF1/BR1) ASV's 
short_asv <- metab_filt[metab_filt$amplicon == "short", ]
uni_short <- length(unique(short_asv$asv_code))
short_asv_reads <- sum(short_asv$reads)

#right amplicon (mICOIintF/dgHCO2198) ASV's 
right_asv <- metab_filt[metab_filt$amplicon == "right", ]
uni_right <- length(unique(right_asv$otu_id))
right_asv_reads <- sum(right_asv$reads)

# total number of ASVs with species identifications
metabar_97 <- subset(metab_filt, max_p_identity >= 97)
num_asv_sp <- length(unique(metabar_97$asv_code))

# calculate the percentage of ASVs with species ids
percentage_asv_id <- num_asv_sp / num_asv *100

# total number of high quality reads
total_reads <- sum(metab_filt$reads)

# total number of high quality reads with species identifications
sp_reads <- sum(metabar_97$reads)

# calculate the percentage of reads with species identifications
percentage_sp_ids <- sp_reads/ total_reads *100

# how many species/families
sp_count <- length(unique(metabar_97$species))
fam_count <- length(unique(metabar_97$family))

# print stats
print(paste("total_reads_used in_analysis =", total_reads))
print(paste("Total_no_of_ASVs =",num_asv))
print(paste("Total_no_of_ASVs_short amplicon_(B/R5)  =", uni_short))
print(paste("Total_no_of_reads_short amplicon_(B/R5)  =", short_asv_reads))
print(paste("Total_no_of_ASVs_right amplicon_(mICOIintF/dgHCO2198)  =", uni_right))
print(paste("Total_no_of_reads_right amplicon_(mICOIintF/dgHCO2198)  =", right_asv_reads))
print(paste("percentage_asv_id_to_species =", percentage_asv_id))
print(paste("percentage of reads with species identifications", percentage_sp_ids))
print(paste("no. of species = ", raw_sp_count))
print(paste("no. of family = ", raw_fam_count))
```
